---
title: "Monte Carlo Chapter"
output:
  html_notebook: default
  pdf_document: default
---

On to simulating the growth of a dollar in our portfolio 

We will revisit these steps in more detail below but briefly we will: 

1) Assume our returns are normally distributed
2) With mean and standard deviation as previously calculated
3) Choose a number of months to simulate and the number of times to run the simulation
4) Write functions to run those simulations in several equivalent ways
5) Visualize our results

Of those 5 steps, number is the only one that requires new substantive work. The other 4 steps build on what we have already done (step 4 does, too, but it's a different application). 

The first step is a crucial one and it bears a bit more discussion.  We make an assumption that the distribution of portfolio returns are normal.  We have done plenty of visualizing of those returns and examined the skewness and kurtosis to see to what extent the returns are not normal. Is the assumption correct? Are the returns normally distributed? For our purposes, we will say yes - but the empirical question of whether we are right or wrong is not the focuso of this book. Rather, the more important point for making our work reproducible is to explicitly declare this assumption, explain where it came from (our work on portfolio returns) and discuss any weaknesses (maybe high skewness or kurtosis which we have already discussed).  The goal is for a team member or end consumer to understand the assumption be able to reproduce any evidence for or against it, and decide independently if the assumption is valid enough to support our simulation.  



What's needed? 
1) price history
2) convert to log returns
3) get mean and st dev if are using normal for simulations
4) first price
5) the function to run them
6) visualize with ggplot (add a mean line? or something? filter to min max mean, get creative here)
7) Cool use case: 
sp500, by sector, or by etf, run the simulations, then joy plot density


```{r}
library(tidyquant)
library(tidyverse)
load("~/reproducible-fin-chapters/book-data.Rdata")
```

Let's start by using our mean and standard deviation calcuation to create simulated monthly returns.  We will use the `rnorm()` function to sample from a distribution with mean equal to `mean(portfolio_returns_tq_rebalanced_monthly$returns)` and standard deviation equal to `sd(portfolio_returns_tq_rebalanced_monthly$returns)`.  How many times should we draw from this distribution? We are using monthly returns and 120 months is 10 years - that feels like a good amount of time to simulate.  

```{r}
mean <- mean(portfolio_returns_tq_rebalanced_monthly$returns)
stddev <- sd(portfolio_returns_tq_rebalanced_monthly$returns)

simulated_monthly_returns <- rnorm(120, mean, stddev)
```

Have a quick look at the simulated monthly returns. 

```{r}
head(simulated_monthly_returns)
tail(simulated_monthly_returns)
```

We want to simulate the growth of a dollar so the first value should be 1. Also, very similar to how we calculated the growth of a dollar in our portfolio, we wan to add a 1 to each of our monthly returns. This will allow us to run cumulative functions.

```{r}
simulated_tibble <- 
  tibble(c(1, 1 + simulated_monthly_returns)) %>% 
  `colnames<-`("returns")

head(simulated_tibble)
```

That object is now ready to be converted into the cumulative growth of a dollar. We can use either `accumulate()` from `purrr` or `cumprod()`. Let's use both of them and confirm consistent, reasonable results. 

```{r}

simulated_growth <- 
simulated_tibble %>%
    mutate(growth1 = accumulate(returns, function(x, y) x * y),
           growth2 = accumulate(returns, `*`),
           growth3 = cumprod(returns)) %>% 
    select(-returns)

cagr <- ((simulated_growth$growth1[nrow(simulated_growth)] ^ (1/10)) -1) * 100

```

The results are consistent. 

Are they reasonable? This simulation indicates our portfolio grew in size to `r simulated_growth$growth1[nrow(simulated_growth)]` over the simulated future 10 years, implying an annual compounded growth of `r cagr`%. That seems reasonable but we've run just one simulation. Let's run more, lots more simulations!

First, we will build simulation functions that incorporate the `accumulate()` and `cumprod()` workflows above. We have confirmed they give consistent results so it's a matter of taste as to which one is chosen in the end. 

Each function needs 4 arguments: N for the number of months to simulate, init_value for the starting value (we used $1 above) and the mean/standard deviation pair to create draws from a normal distribution. We choose N and init_value, and derive the mean/sd pair from our portfolio monthly returns object. 

Here is our first growth simulation function using `accumulate()`

```{r}

simulation_accum_1 <- function(init_value, N, mean, stdev) {
    tibble(c(init_value, 1 + rnorm(N, mean, stdev))) %>% 
    `colnames<-`("returns") %>%
    mutate(growth = accumulate(returns, function(x, y) x * y)) %>% 
    select(growth)
}
```

Almost identical, here is the second simulation function using `accumulate()`.

```{r}

simulation_accum_2 <- function(init_value, N, mean, stdev) {
  tibble(c(init_value, 1 + rnorm(N, mean, stdev))) %>% 
    `colnames<-`("returns") %>%
  mutate(growth = accumulate(returns, `*`)) %>% 
  select(growth)
}
```

Finally, here is a simulation function using `cumprod()`.

```{r}
simulation_cumprod <- function(init_value, N, mean, stdev) {
  tibble(c(init_value, 1 + rnorm(N, mean, stdev))) %>% 
    `colnames<-`("returns") %>%
  mutate(growth = cumprod(returns)) %>% 
  select(growth)
}
```
Here is a function that uses all three methods, in case we want a fast way to re-confirm consistency. 

```{r}

simulation_confirm_all <- function(init_value, N, mean, stdev) {
  tibble(c(init_value, 1 + rnorm(N, mean, stdev))) %>% 
    `colnames<-`("returns") %>%
    mutate(growth1 = accumulate(returns, function(x, y) x * y),
           growth2 = accumulate(returns, `*`),
           growth3 = cumprod(returns)) %>% 
    select(-returns)
}
```

Let's test that `confirm_all()` function with an init_value of 1, N of 10, and our mean/sd pair

```{r}
simulation_confirm_all(1, 10, mean, stddev)
```

Alright, another successful confirmation, this time with a function.  

Now we are ready to run more than one simulation. 

First, we'll need an object to hold all these simulations. Let's creat an empty matrix with 51 columns, an initial value of 1 and intuitive column names. Why 51 instead of 50? I want the median simulation to have a value that maps to an actual simulation. 

```{r}
sims <- 51
starts <- 
  rep(1, sims) %>%
  set_names(paste("sim", 1:sims, sep = ""))
```

Take a peek at the `starts` object. 

```{r}
head(starts)
```
 This is where we'll store the results of the 51 simulations.
 
 Now we want to apply one of our simulation functions to each of the 51 columns of the `starts` matrix and we will do that using the `map_dfc()` function from the `purrr` package. `map_dfc` will take a vector, in this case the row of 1's in the `starts` object and apply a function to it, in this case whichever simulation function we choose.  By appending `_dfc()` to the base `map()` function, we are asking the function to store each of its results as the column of a dataframe. After running the code flow, we will have a dataframe with 51 columns, one for each of our simulations. We need to choose how many months to simulate (the N argument to our simulation function) and supply the mean/sd pair before. 


```{r}
monte_carlo_simd_1 <- 
  map_dfc(starts, simulation_accum_1, N = 120, mean = mean, stdev = stddev)

tail(monte_carlo_simd_1)
```

Have a look at the results. We now have 51 simulations of the growth of a dollar! Let's add one more piece to help with charting. We simulated 120 months so let's add a column, called `month` that is numbered 1 through 120.  We will use `mutate(month = seq(1:nrow(.)))` and then clean up the column names and order.

```{r}
monte_carlo_simd_1 <- 
  map_dfc(starts, simulation_accum_1, N = 120, mean = mean, stdev = stddev) %>% 
  mutate(month = seq(1:nrow(.))) %>% 
  select(month, everything()) %>% 
  `colnames<-`(c("month", names(starts)))

tail(monte_carlo_simd_1)
```

Now we have 51 columns of simulations and 1 column of months. Note that we have 121 rows because we started with an intitial value of $1, and then simulated returns over 120 months. 

Let's visualize the results with `ggplot()` - the fun part of simulation. We'll start with a chart of all 51 simulations and give different color to each one by setting `ggplot(aes(x = month, y = growth, color = sim))`.  `ggplot()` will automatically generate a legend for all 51 time series but that gets quite crowded. We will suppress the legend with `theme(legend.position="none")`.

```{r}
monte_carlo_simd_1 %>% 
  gather(sim, growth, -month) %>% 
  group_by(sim) %>% 
  ggplot(aes(x = month, y = growth, color = sim)) + 
  geom_line() +
  theme(legend.position="none")
```


Alright, we see quite a range of returns. Let's check the minimum, maximum and median simulation. 

```{r}

sim_summary <- 
monte_carlo_simd_1 %>% 
  gather(sim, growth, -month) %>% 
  group_by(sim) %>% 
  summarise(final = last(growth)) %>% 
  summarise(
            max = max(final), 
            min = min(final),
            median = median(final))
sim_summary
```

The range is `r sim_summary$max` to `r sim_summary$min`. 

How do our quantiles look? 

```{r}
probs <- c(.005, .025, .25, .5, .75, .975, .995)

sim_final_quantile <- 
monte_carlo_simd_1 %>% 
  gather(sim, growth, -month) %>% 
  group_by(sim) %>% 
  summarise(final = last(growth))

quantiles <- 
  round(quantile(sim_final_quantile$final, probs = probs), 2) %>% 
  tibble() %>%
  `colnames<-`("value") %>% 
  mutate(probs = probs) %>% 
    spread(probs, value)
quantiles[,1:6]
```

Huzzah! Our 95% confidence interval for the growth of a dollar is between `r quantiles[,2]` and `r quantiles[,6]`. 

Our .5% super outlier negative result is `r quantiles[,1]`. 

Are we the Brunelleschi of portfolio construction? Or have we based our assumptions off of returns during an unstoppable bull market that's been chugging along since well before 2013? When we get to Shiny and let users choose different start dates, we will find out the hard but inescapable truth about our own genius and how it relates to bull markets.

We can isolate or eliminate some of the noise from our simulations and pull out certain time series. We have already calculated the maximum, minimum and median end growth values. Let's use `filter(any())` from `dplyr` to isolate those three simulations and then visualizd with `ggplot`. 

```{r}
monte_carlo_simd_1 %>% 
  gather(sim, growth, -month) %>% 
  group_by(sim) %>%
  filter(
      any(growth == sim_summary$max) || 
      any(growth == sim_summary$median) ||
      any(growth == sim_summary$min)) %>% 
  ggplot(aes(x = month, y = growth)) + 
  geom_line(aes(color = sim))
```


```{r}
 
monte_carlo_simd_1 %>% 
  gather(sim, growth, -month) %>% 
  group_by(sim) %>% 
  summarise(final = last(growth)) %>% 
  ggplot(aes(x = final)) +
  geom_histogram(color = "cornflowerblue", fill = "cornflowerblue", binwidth = .05)
```



## Shiny
1) build portfolio
2) get returns, mean, std dev
3) display results
4) display high, low, median
5) histogram of or scatter of end values? 
6) Quantiles
